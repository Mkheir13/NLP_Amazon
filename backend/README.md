# Backend NLP - BERT & NLTK Training

Backend Python Flask pour l'entraÃ®nement de modÃ¨les BERT et l'analyse de sentiment avec NLTK.

## ğŸš€ Installation

1. **CrÃ©er un environnement virtuel** :
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows
```

2. **Installer les dÃ©pendances** :
```bash
pip install -r requirements.txt
```

3. **CrÃ©er les modÃ¨les de base** :
```bash
python create_models.py
```

4. **TÃ©lÃ©charger les donnÃ©es NLTK** :
```python
import nltk
nltk.download('vader_lexicon')
```

## ğŸƒâ€â™‚ï¸ Lancement

### MÃ©thode 1 : Script automatique
```bash
# Windows
start_backend.bat

# Linux/Mac
chmod +x start_backend.sh
./start_backend.sh
```

### MÃ©thode 2 : Manuel
```bash
cd backend
python app.py
```

Le serveur dÃ©marre sur `http://localhost:5000`

## ğŸ“ Structure des ModÃ¨les

Les modÃ¨les BERT sont stockÃ©s dans `backend/models/` mais ne sont pas inclus dans Git Ã  cause de leur taille (plusieurs GB).

### RecrÃ©er les modÃ¨les manquants

Si vous clonez le repository et que le dossier `models/` est vide :

```bash
cd backend
python create_models.py
```

Ce script va :
- TÃ©lÃ©charger DistilBERT de base depuis Hugging Face
- CrÃ©er la structure de dossiers nÃ©cessaire
- GÃ©nÃ©rer les fichiers de configuration
- PrÃ©parer le modÃ¨le pour l'entraÃ®nement via l'interface web

## ğŸ”§ API Endpoints

- `GET /api/health` - Status du serveur
- `POST /api/train/bert` - EntraÃ®ner un modÃ¨le BERT
- `POST /api/analyze/nltk` - Analyser avec NLTK VADER
- `GET /api/models` - Liste des modÃ¨les disponibles
- `POST /api/predict/bert` - PrÃ©diction avec BERT

## ğŸ“Š FonctionnalitÃ©s

### BERT Training
- Support DistilBERT, BERT, RoBERTa
- Configuration personnalisable (epochs, batch size, learning rate)
- MÃ©triques complÃ¨tes (accuracy, precision, recall, F1)
- Sauvegarde automatique des checkpoints

### NLTK Analysis
- Sentiment analysis avec VADER
- Scores dÃ©taillÃ©s (positive, negative, neutral, compound)
- Analyse en temps rÃ©el

## ğŸ¯ Utilisation

1. **Lancer le backend** : `python app.py`
2. **Lancer le frontend** : `npm run dev` (dans le dossier racine)
3. **Aller sur** : `http://localhost:5173`
4. **Naviguer vers** : "EntraÃ®ner ModÃ¨les"
5. **Configurer et entraÃ®ner** vos modÃ¨les !

## ğŸ” DÃ©pannage

### Erreur "No models found"
```bash
python create_models.py
```

### Erreur NLTK
```python
import nltk
nltk.download('vader_lexicon')
```

### Erreur de dÃ©pendances
```bash
pip install -r requirements.txt
```

## ğŸ“š Technologies

- **Flask** : Serveur web Python
- **Transformers** : ModÃ¨les BERT (Hugging Face)
- **NLTK** : Analyse de sentiment VADER
- **PyTorch** : Framework de deep learning
- **Datasets** : Gestion des datasets (Hugging Face)

## ğŸ“¡ Endpoints API

### SantÃ© du serveur
- **GET** `/api/health` - VÃ©rifier l'Ã©tat du serveur

### EntraÃ®nement BERT
- **POST** `/api/train/bert` - EntraÃ®ner un modÃ¨le BERT

**Body :**
```json
{
  "data": [
    {"text": "Great product!", "label": 1, "sentiment": "positive"},
    {"text": "Terrible quality", "label": 0, "sentiment": "negative"}
  ],
  "config": {
    "model_name": "distilbert-base-uncased",
    "epochs": 3,
    "batch_size": 8,
    "learning_rate": 2e-5,
    "test_size": 0.2
  }
}
```

### Analyse NLTK
- **POST** `/api/analyze/nltk` - Analyser un texte avec NLTK VADER

**Body :**
```json
{
  "text": "This is a great product!"
}
```

- **POST** `/api/analyze/nltk/batch` - Analyser plusieurs textes

**Body :**
```json
{
  "texts": ["Great product!", "Terrible quality"]
}
```

### Gestion des modÃ¨les
- **GET** `/api/models` - RÃ©cupÃ©rer la liste des modÃ¨les entraÃ®nÃ©s
- **POST** `/api/predict/bert/{model_id}` - PrÃ©diction avec un modÃ¨le BERT

## ğŸ”§ Configuration

### ModÃ¨les supportÃ©s
- `distilbert-base-uncased` (RecommandÃ© pour dÃ©buter)
- `bert-base-uncased`
- `roberta-base`

### ParamÃ¨tres d'entraÃ®nement
- **epochs** : Nombre d'Ã©poques (1-10)
- **batch_size** : Taille des lots (4-32)
- **learning_rate** : Taux d'apprentissage (1e-5 Ã  5e-5)
- **test_size** : Pourcentage pour le test (0.1-0.5)

## ğŸ“ Structure des fichiers

```
backend/
â”œâ”€â”€ app.py              # Serveur Flask principal
â”œâ”€â”€ requirements.txt    # DÃ©pendances Python
â”œâ”€â”€ models/            # ModÃ¨les BERT entraÃ®nÃ©s
â”œâ”€â”€ logs/              # Logs d'entraÃ®nement
â””â”€â”€ README.md          # Ce fichier
```

## âš ï¸ Notes importantes

1. **GPU recommandÃ©** : L'entraÃ®nement BERT est beaucoup plus rapide avec un GPU
2. **MÃ©moire** : BERT nÃ©cessite au moins 4GB de RAM
3. **Temps d'entraÃ®nement** : Peut prendre 10-30 minutes selon le dataset et le matÃ©riel
4. **Stockage** : Chaque modÃ¨le fait environ 250MB

## ğŸ› DÃ©pannage

### Erreur de mÃ©moire
RÃ©duisez le `batch_size` Ã  4 ou moins.

### ModÃ¨le trop lent
Utilisez `distilbert-base-uncased` au lieu de `bert-base-uncased`.

### Erreur CUDA
Si vous n'avez pas de GPU, PyTorch utilisera automatiquement le CPU.

## ğŸ“Š MÃ©triques retournÃ©es

AprÃ¨s l'entraÃ®nement, vous obtenez :
- **Accuracy** : PrÃ©cision globale
- **Precision** : PrÃ©cision par classe
- **Recall** : Rappel par classe  
- **F1-Score** : Score F1 pondÃ©rÃ©
- **Eval Loss** : Perte sur le set de validation 