# ðŸŒŸ NLP Amazon Analysis - Interface Web ComplÃ¨te

## ðŸŽ¯ Vue d'ensemble

Interface web complÃ¨te pour l'analyse NLP avec autoencodeur sur le dataset Amazon/Polarity. **TOUTES** les fonctionnalitÃ©s sont disponibles directement sur le site web !

## ðŸš€ DÃ©marrage Rapide

### 1. Backend (Terminal 1)
```bash
cd backend
python app.py
```
âœ… Backend disponible sur `http://localhost:5000`

### 2. Frontend (Terminal 2)
```bash
npm run dev
```
âœ… Interface web disponible sur `http://localhost:5177` (ou 5173-5176 selon disponibilitÃ©)

### 3. Test Complet (Terminal 3)
```bash
python test_complete_functionality.py
```
âœ… VÃ©rifie que toutes les fonctionnalitÃ©s fonctionnent

## ðŸŒŸ FonctionnalitÃ©s de l'Interface Web

### **Onglet 1: EntraÃ®nement**
- âœ… Configuration des hyperparamÃ¨tres
- âœ… **EntraÃ®nement standard** ou **optimisÃ©** (Data Science)
- âœ… Ã‰valuation de qualitÃ© en temps rÃ©el
- âœ… Chargement automatique du dataset Amazon
- âœ… MÃ©triques complÃ¨tes (MSE, MAE, RMSE, similaritÃ©, variance)

### **Onglet 2: Test**
- âœ… Reconstruction de texte personnalisÃ©
- âœ… Visualisation des embeddings
- âœ… **Codes sources intÃ©grÃ©s** avec copie en un clic
- âœ… Analyse des termes importants

### **Onglet 3: Clustering**
- âœ… KMeans avec mÃ©triques avancÃ©es
- âœ… **Auto-optimisation** du nombre de clusters
- âœ… Analyse dÃ©taillÃ©e des clusters
- âœ… Score de silhouette, inertie, interprÃ©tation

### **Onglet 4: AvancÃ©** â­ NOUVEAU
- âœ… **MÃ©triques Data Science niveau M1**:
  - Silhouette Score, Calinski-Harabasz, Davies-Bouldin
- âœ… **Sauvegarde/chargement** de modÃ¨les
- âœ… **Analyse sÃ©mantique** complÃ¨te
- âœ… Sentiment analysis et identification de thÃ¨mes

### **Onglet 5: Recherche**
- âœ… Recherche sÃ©mantique dans l'espace compressÃ©
- âœ… SimilaritÃ© cosinus, top-K rÃ©sultats

### **Onglet 6: Info ModÃ¨le**
- âœ… Ã‰tat du systÃ¨me en temps rÃ©el
- âœ… Configuration JSON complÃ¨te

## ðŸŽ“ Concepts Data Science ImplÃ©mentÃ©s

### **Architecture Autoencoder OptimisÃ©e**
- **Compression intelligente**: 2000D â†’ 256D
- **Normalisation L2** appropriÃ©e pour TF-IDF
- **RÃ©gularisation L2** + dropout progressif
- **Preprocessing NLTK** avancÃ© (lemmatisation, stop words)

### **MÃ©triques AvancÃ©es**
- **QualitÃ© reconstruction**: MSE, MAE, RMSE
- **Clustering**: Silhouette, Calinski-Harabasz, Davies-Bouldin
- **SÃ©mantique**: SimilaritÃ© cosinus, variance expliquÃ©e
- **Optimisation**: MÃ©thode du coude + silhouette

### **Pipeline Complet (7 Ã‰tapes)**
1. **Corpus**: Dataset Amazon/Polarity
2. **Vectorisation**: TF-IDF optimisÃ© (trigrammes)
3. **Autoencoder**: Architecture avec rÃ©gularisation
4. **EntraÃ®nement**: X â†’ X avec Ã©valuation
5. **Extraction**: Vecteurs compressÃ©s (X_encoded)
6. **KMeans**: Clustering sur espace compressÃ©
7. **Analyse**: InterprÃ©tation des clusters

## ðŸ“Š MÃ©triques et InterprÃ©tations

### **Score de QualitÃ© Global**
- **Excellent (0.8+)**: Reconstruction quasi-parfaite
- **Bon (0.6-0.8)**: TrÃ¨s bonne compression
- **Moyen (0.4-0.6)**: âœ… **Normal pour du texte**
- **Faible (0.0-0.4)**: ProblÃ¨me d'architecture

### **Score de Silhouette**
- **> 0.5**: Clusters excellents
- **0.3-0.5**: Clusters bons
- **0.1-0.3**: âœ… **Acceptable pour du texte**
- **< 0.1**: Clusters faibles

## ðŸŽ¯ Utilisation RecommandÃ©e

### **Pour Commencer**
1. **Aller sur** `http://localhost:5177`
2. **Onglet "EntraÃ®nement"** â†’ Cocher "Utiliser l'entraÃ®nement optimisÃ©"
3. **Cliquer "EntraÃ®nement OptimisÃ©"** puis **"Ã‰valuer QualitÃ©"**
4. **Onglet "Clustering"** â†’ Cliquer **"Auto-Optimiser"** puis **"Lancer Clustering"**
5. **Onglet "AvancÃ©"** â†’ Cliquer **"Analyse ComplÃ¨te"**

### **RÃ©sultats Attendus**
- **Score de qualitÃ©**: Moyen (0.4-0.6) pour le dataset Amazon
- **Silhouette**: 0.1-0.3 (acceptable pour des avis textuels)
- **Clusters recommandÃ©s**: k=2 ou k=3
- **Compression**: 1.5-2x (efficace)

## ðŸ”§ Structure du Projet

```
NLP_Amazon/
â”œâ”€â”€ backend/                 # API Flask
â”‚   â”œâ”€â”€ app.py              # Serveur principal
â”‚   â”œâ”€â”€ config.py           # Configuration centralisÃ©e
â”‚   â”œâ”€â”€ models/             # Services ML
â”‚   â””â”€â”€ requirements.txt    # DÃ©pendances Python
â”œâ”€â”€ src/                    # Interface React
â”‚   â”œâ”€â”€ components/         # Composants UI
â”‚   â””â”€â”€ services/           # Services frontend
â”œâ”€â”€ data/                   # Dataset Amazon/Polarity
â””â”€â”€ models/                 # ModÃ¨les sauvegardÃ©s
```

## ðŸ”§ API Endpoints Disponibles

### **EntraÃ®nement**
- `POST /api/autoencoder/train` - EntraÃ®nement standard
- `POST /api/autoencoder/train_optimized` - EntraÃ®nement optimisÃ©

### **Ã‰valuation**
- `POST /api/autoencoder/evaluate` - Ã‰valuation complÃ¨te
- `GET /api/autoencoder/info` - Informations du modÃ¨le

### **Clustering**
- `POST /api/autoencoder/kmeans` - Clustering basique
- `POST /api/autoencoder/clustering_advanced` - Analyse avancÃ©e
- `POST /api/autoencoder/optimize_clusters` - Optimisation auto

### **Gestion ModÃ¨les**
- `POST /api/autoencoder/save` - Sauvegarder modÃ¨le
- `POST /api/autoencoder/load` - Charger modÃ¨le

### **Utilisation**
- `POST /api/autoencoder/reconstruct` - Reconstruction de texte
- `POST /api/autoencoder/search` - Recherche sÃ©mantique

## ðŸ†˜ DÃ©pannage

### **ProblÃ¨me 1: Backend ne dÃ©marre pas**
```bash
cd backend
pip install -r requirements.txt
python app.py
```

### **ProblÃ¨me 2: Erreurs 500 dans les tests**
- VÃ©rifiez les logs du backend (Terminal 1)
- RedÃ©marrez le backend si nÃ©cessaire

### **ProblÃ¨me 3: Frontend ne se connecte pas**
- VÃ©rifiez que le port correspond (Backend=5000, Frontend=5177)

### **Test Rapide**
```bash
# Test API
curl http://localhost:5000/api/health

# Test Frontend
# Ouvrir: http://localhost:5177
```

## ðŸŽ‰ FonctionnalitÃ©s ClÃ©s

âœ… **Interface web complÃ¨te** avec 6 onglets fonctionnels  
âœ… **12 endpoints API** pour toutes les fonctionnalitÃ©s  
âœ… **MÃ©triques Data Science** niveau Master  
âœ… **Sauvegarde/chargement** de modÃ¨les  
âœ… **Optimisation automatique** des hyperparamÃ¨tres  
âœ… **Codes sources** intÃ©grÃ©s pour apprentissage  
âœ… **Tests automatiques** pour validation  

## ðŸ“‹ Technologies UtilisÃ©es

- **Frontend**: React + TypeScript + Vite + Tailwind CSS
- **Backend**: Flask + NumPy + scikit-learn + NLTK
- **ML**: Autoencoder (NumPy), TF-IDF, KMeans
- **Dataset**: Amazon/Polarity (avis clients)

---

**ðŸŒ AccÃ©dez Ã  l'interface**: `http://localhost:5177`  
**ðŸ”§ Testez tout**: `python test_complete_functionality.py`  

**Le projet est maintenant 100% fonctionnel avec toutes les fonctionnalitÃ©s avancÃ©es ! ðŸš€**